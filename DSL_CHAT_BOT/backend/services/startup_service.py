import pandas as pd
import numpy as np
import re
from collections import Counter
from models.embedding_model import embedding_instance
from models.llm_model import llm_instance
from utils.text_processor import text_processor
from config.settings import DATA_PATHS

class StartupService:
    def __init__(self):
        self.embedder = embedding_instance
        self.llm = llm_instance
        self.text_processor = text_processor
        self.stats_corpus = []  # í†µê³„ ë°ì´í„° ì „ìš©
        self.biz_corpus = []    # ì‚¬ì—…ì¥ ë°ì´í„° ì „ìš©
        self.stats_embeds = None
        self.biz_embeds = None
        self._load_data()
    
    def _load_data(self):
        try:
            # 1. í†µê³„ ë°ì´í„° ë¡œë“œ
            df_stats = pd.read_csv(DATA_PATHS['startup_data'], encoding="utf-8")
            self.stats_corpus = [self.text_processor.row_to_text(row) for _, row in df_stats.iterrows()]
            
            # 2. ì‚¬ì—…ì¥ ë°ì´í„° ë¡œë“œ (í—¤ë” ìŠ¤í‚µ)
            df_biz = pd.read_csv(DATA_PATHS['business_data'], encoding="utf-8", header=None)
            self.biz_corpus = [self.text_processor.business_row_to_text(row) for idx, row in df_biz.iterrows() if idx > 0]
            
            # 3. ë¶„ë¦¬ ì„ë² ë”© ìƒì„±
            print("í†µê³„ ë°ì´í„° ì„ë² ë”© ìƒì„± ì¤‘...")
            self.stats_embeds = self.embedder.encode(
                self.stats_corpus, 
                convert_to_numpy=True,
                show_progress_bar=True
            )
            
            print("ì‚¬ì—…ì¥ ë°ì´í„° ì„ë² ë”© ìƒì„± ì¤‘...")
            self.biz_embeds = self.embedder.encode(
                self.biz_corpus,
                convert_to_numpy=True,
                show_progress_bar=True
            )
            
            print("âœ”ï¸ ì„ë² ë”© ìƒì„± ì™„ë£Œ")
            
        except Exception as e:
            print(f"âŒ ë°ì´í„° ë¡œë“œ ì˜¤ë¥˜: {e}")
            # í´ë°±: í†µê³„ ë°ì´í„°ë§Œ ë¡œë“œ + ì•ˆì „í•œ ì„ë² ë”© ìƒì„±
            try:
                df_stats = pd.read_csv(DATA_PATHS['startup_data'], encoding="utf-8")
                self.stats_corpus = [self.text_processor.row_to_text(row) for _, row in df_stats.iterrows()]
                self.biz_corpus = []
                
                # ğŸ”¥ ì¤‘ìš”: í´ë°±ì—ì„œë„ ì„ë² ë”© ìƒì„±
                print("í´ë°±: í†µê³„ ë°ì´í„° ì„ë² ë”© ìƒì„± ì¤‘...")
                self.stats_embeds = self.embedder.encode(
                    self.stats_corpus, 
                    convert_to_numpy=True, 
                    show_progress_bar=True
                )
                self.biz_embeds = np.array([])  # ë¹ˆ ë°°ì—´ë¡œ ì´ˆê¸°í™”
                print("âœ”ï¸ í´ë°± ì„ë² ë”© ì™„ë£Œ")
                
            except Exception as fallback_e:
                print(f"âŒ í´ë°± ë¡œë“œë„ ì‹¤íŒ¨: {fallback_e}")
                # ìµœí›„ì˜ ìˆ˜ë‹¨: ë¹ˆ ë°ì´í„°ë¡œ ì´ˆê¸°í™”
                self.stats_corpus = []
                self.biz_corpus = []
                self.stats_embeds = np.array([])
                self.biz_embeds = np.array([])

    def detect_main_sector(self, question):
        """ì§ˆë¬¸ì—ì„œ ê°€ì¥ ê´€ë ¨ ë†’ì€ ì—…ì¢… 1ê°œë§Œ ì¶”ì¶œ"""
        text_key = question.lower()
        matched_sectors = []
        
        # 1. ë™ì˜ì–´ ê¸°ë°˜ ë§¤ì¹­
        for sector, keywords in self.text_processor.SYNONYMS.items():
            for keyword in keywords:
                if keyword.lower() in text_key:
                    matched_sectors.append(sector)
        
        # 2. ì—…ì¢…ëª… ì§ì ‘ ë§¤ì¹­
        for sector in self.text_processor.SYNONYMS.keys():
            if sector.lower() in text_key:
                matched_sectors.append(sector)
        
        # 3. ë§¤ì¹­ëœ ì—…ì¢…ì´ ìˆìœ¼ë©´ ê°€ì¥ ë¹ˆë„ ë†’ì€ ê²ƒ ì„ íƒ
        if matched_sectors:
            sector_counter = Counter(matched_sectors)
            return sector_counter.most_common(1)[0][0]
        
        return "ê¸°íƒ€"

    def get_sector_statistics(self, sector):
        """íŠ¹ì • ì—…ì¢…ì˜ ëª¨ë“  í†µê³„ ë°ì´í„° ì¶”ì¶œ ë° ì •ë ¬"""
        all_sector_stats = [
            stat for stat in self.stats_corpus 
            if f"[í†µê³„]" in stat and sector.lower() in stat.lower()
        ]
        
        # ì—°ë„ë³„ ì •ë ¬ (2020 â†’ 2025)
        all_sector_stats_sorted = sorted(
            all_sector_stats,
            key=lambda x: int(re.search(r'(\d{4})ë…„', x).group(1)) if re.search(r'(\d{4})ë…„', x) else 0,
            reverse=True   # ì´ ë¶€ë¶„ì´ í•µì‹¬!
        )
        return all_sector_stats_sorted

    def get_sector_businesses(self, sector, user_keywords):
        """íŠ¹ì • ì—…ì¢…ì˜ ì‚¬ì—…ì¥ ë°ì´í„°ë¥¼ ìš°ì„ ìˆœìœ„ì— ë”°ë¼ ì„ ë³„"""
        # í•´ë‹¹ ì—…ì¢…ì˜ ì‚¬ì—…ì¥ ë°ì´í„°
        biz_examples = [
            biz for biz in self.biz_corpus 
            if f"[ì‚¬ì—…ì¥]" in biz and sector.lower() in biz.lower()
        ]
        
        # ì‚¬ìš©ì í‚¤ì›Œë“œê°€ í¬í•¨ëœ ì‚¬ì—…ì¥ ìš°ì„  ì„ íƒ
        keyword_matches = []
        other_matches = []
        
        for biz in biz_examples:
            # ì‚¬ì—…ì¥ ì´ë¦„ ì¶”ì¶œ
            name_match = re.search(r'\[ì‚¬ì—…ì¥\] ([^\(]+)', biz)
            name = name_match.group(1).strip() if name_match else ""
            
            # ìƒíƒœ ì •ë³´ ì¶”ì¶œ
            status = ""
            if "ì˜ì—…" in biz:
                status = "ì˜ì—…"
            elif "íì—…" in biz:
                status = "íì—…"
            elif "ì·¨ì†Œ" in biz:
                status = "ì·¨ì†Œ"
            else:
                status_match = re.search(r'\([^,]+,\s*([^\)]+)\)', biz)
                if status_match:
                    status = status_match.group(1).strip()
            
            # í‚¤ì›Œë“œ ë§¤ì¹­
            matched = False
            for kw in user_keywords:
                if kw.lower() in name.lower():
                    matched = True
                    break
            
            if matched:
                keyword_matches.append((name, status))
            else:
                other_matches.append((name, status))
        
        # ì˜ì—…/íì—… ìƒíƒœë³„ í•„í„°ë§
        open_keyword = [b for b in keyword_matches if "ì˜ì—…" in b[1]]
        open_others = [b for b in other_matches if "ì˜ì—…" in b[1]]
        closed_keyword = [b for b in keyword_matches if "íì—…" in b[1]]
        closed_others = [b for b in other_matches if "íì—…" in b[1]]
        
        # 3ê°œ ìš°ì„  ì„ íƒ: í‚¤ì›Œë“œ ì˜ì—… > ì¼ë°˜ ì˜ì—… > í‚¤ì›Œë“œ íì—… > ì¼ë°˜ íì—…
        selected = []
        
        selected.extend(open_keyword[:min(3, len(open_keyword))])
        
        if len(selected) < 3:
            needed = 3 - len(selected)
            selected.extend(open_others[:min(needed, len(open_others))])
        
        if len(selected) < 3:
            needed = 3 - len(selected)
            selected.extend(closed_keyword[:min(needed, len(closed_keyword))])
        
        if len(selected) < 3:
            needed = 3 - len(selected)
            selected.extend(closed_others[:min(needed, len(closed_others))])
        
        return selected, len(biz_examples)

    def analyze_question(self, question):
        """ì§ˆë¬¸ ì¢…í•© ë¶„ì„ (ì½”ë©ì˜ inspect_question ë¡œì§)"""
        # ì£¼ ì—…ì¢… ê°ì§€
        main_sector = self.detect_main_sector(question)
        
        # í‚¤ì›Œë“œ ì •ë³´
        sector_keywords = self.text_processor.SYNONYMS.get(main_sector, [])
        
        # ì‚¬ìš©ì ì§ˆë¬¸ì—ì„œ ì§ì ‘ ì–¸ê¸‰ëœ í‚¤ì›Œë“œ ì¶”ì¶œ
        user_keywords = []
        question_lower = question.lower()
        for keyword in sector_keywords + [main_sector]:
            if re.search(rf'\b{re.escape(keyword.lower())}\b', question_lower):
                user_keywords.append(keyword)
        
        # í•´ë‹¹ ì—…ì¢… í†µê³„ ë°ì´í„°
        statistics = self.get_sector_statistics(main_sector)
        
        # í•´ë‹¹ ì—…ì¢… ì‚¬ì—…ì¥ ì‚¬ë¡€
        business_examples, total_businesses = self.get_sector_businesses(main_sector, user_keywords)
        
        return {
            "sector": main_sector,
            "keywords": sector_keywords,
            "user_keywords": user_keywords,
            "statistics": statistics,
            "business_examples": business_examples,
            "total_businesses": total_businesses
        }

    def enhanced_search_context(self, question):
        """ì—…ì¢… ë¶„ì„ ê¸°ë°˜ í–¥ìƒëœ ì»¨í…ìŠ¤íŠ¸ ê²€ìƒ‰"""
        # ê¸°ë³¸ ì„ë² ë”© ê²€ìƒ‰
        basic_contexts = self.search_context(question, topk_stats=5, topk_biz=3)
        
        # ì§ˆë¬¸ ë¶„ì„
        analysis = self.analyze_question(question)
        
        # ë¶„ì„ëœ ì—…ì¢…ì˜ ëª¨ë“  í†µê³„ ë°ì´í„° ì¶”ê°€
        sector_stats = analysis["statistics"]
        
        # ì¤‘ë³µ ì œê±°í•˜ë©´ì„œ í†µí•©
        all_contexts = []
        
        # 1. ì—…ì¢…ë³„ í†µê³„ ë°ì´í„° ìš°ì„  ì¶”ê°€
        for stat in sector_stats[:3]:  # ìµœê·¼ 3ë…„ ë°ì´í„°ë§Œ
            if stat not in all_contexts:
                all_contexts.append(stat)
        
        # 2. ê¸°ë³¸ ì„ë² ë”© ê²€ìƒ‰ ê²°ê³¼ ì¶”ê°€ (ì¤‘ë³µ ì œê±°)
        for context in basic_contexts:
            if context not in all_contexts:
                all_contexts.append(context)
        
        return all_contexts[:8]  # ìµœëŒ€ 8ê°œë¡œ ì œí•œ

    def search_context(self, query, topk_stats=5, topk_biz=3):
        """í†µê³„ ë°ì´í„°ì™€ ì‚¬ì—…ì¥ ë°ì´í„°ë¥¼ ë³„ë„ë¡œ ê²€ìƒ‰"""
        q_emb = self.embedder.encode(query, convert_to_numpy=True)
        
        # 1. í†µê³„ ë°ì´í„° ê²€ìƒ‰ (ìƒìœ„ 5ê°œ)
        stats_results = []
        if len(self.stats_embeds) > 0:  # ğŸ”¥ ì•ˆì „ ê²€ì‚¬ ì¶”ê°€
            stats_sims = np.dot(self.stats_embeds, q_emb)
            stats_ids = stats_sims.argsort()[-topk_stats:][::-1]
            stats_results = [self.stats_corpus[i] for i in stats_ids]
        
        # 2. ì‚¬ì—…ì¥ ë°ì´í„° ê²€ìƒ‰ (ë°ì´í„° ì¡´ì¬ì‹œ)
        biz_results = []
        if len(self.biz_embeds) > 0:  # ğŸ”¥ ì„ë² ë”© ì¡´ì¬ ì—¬ë¶€ í™•ì¸
            biz_sims = np.dot(self.biz_embeds, q_emb)
            biz_ids = biz_sims.argsort()[-topk_biz:][::-1]
            biz_results = [self.biz_corpus[i] for i in biz_ids]
        
        return stats_results + biz_results

    def llm_answer_with_rag(self, question, chat_history=None):
        # 1. ì»¨í…ìŠ¤íŠ¸ ê²€ìƒ‰
        contexts = self.enhanced_search_context(question)
        if not contexts:
            return """ì•ˆë…•í•˜ì„¸ìš”! ëŒ€êµ¬ ë™ì„±ë¡œ ì°½ì—… ì§€ì› ì±—ë´‡ì…ë‹ˆë‹¤.
#                 ì£„ì†¡í•˜ì§€ë§Œ ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ìë£Œë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.
#                 ë” êµ¬ì²´ì ì¸ í‚¤ì›Œë“œë¡œ ë‹¤ì‹œ ì§ˆë¬¸í•´ì£¼ì„¸ìš”.
#                 ì˜ˆì‹œ: "ë™ì„±ë¡œ ì¹´í˜ ì°½ì—…ë¥ ì€?", "ì¹˜í‚¨ì§‘ íì—…ë¥  í†µê³„ëŠ”?"
#                 """

        # 2. ì§ˆë¬¸ ë¶„ì„
        analysis = self.analyze_question(question)

        # 3. í•µì‹¬ í†µê³„ ë¶€ë¶„ ì§ì ‘ í¬ë§·íŒ… (ì—°ë„ ì˜¤ë¦„ì°¨ìˆœ ì •ë ¬ í¬í•¨)
        stats_with_year = []
        for stat in analysis['statistics'][:6]:  # 2020~2025 6ë…„ì¹˜
            match = re.match(r'\[í†µê³„\]\s*(\d{4})ë…„.*?:\s*(.+)', stat)
            if match:
                year, rest = match.groups()
                stats_with_year.append((int(year), f"**{year}ë…„**: {rest.strip()}"))

        # ì—°ë„ ì˜¤ë¦„ì°¨ìˆœ ì •ë ¬
        stats_with_year.sort(key=lambda x: x[0])

        # ì •ë ¬ í›„ stats_lines ë§Œë“¦
        stats_lines = [line for _, line in stats_with_year]

        # 4. ëŒ€í‘œ ì‚¬ì—…ì¥ ì •í˜•í™” ì¶œë ¥ (ìµœëŒ€ 3ê°œ)
        biz_lines = []
        for name, status in analysis.get('business_examples', [])[:3]:
            biz_lines.append(f"{len(biz_lines)+1}. {name} ({status})")
        if not biz_lines:
            biz_lines.append("ë°ì´í„° ì—†ìŒ")

        # 5. LLMì— ë³´ë‚¼ ê°„ë‹¨ ìš”ì•½ ë¬¸ìì—´ ìƒì„±
        stats_summary = " / ".join([line.split(": ",1)[1] for line in stats_lines]) or "í†µê³„ ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤."

        prompt = (
            "í˜„ì¬ ì‹œì : 2025ë…„ 8ì›”\n"
            "ë‹¹ì‹ ì€ ëŒ€êµ¬ ë™ì„±ë¡œ ì°½ì—… ì „ë¬¸ê°€ì…ë‹ˆë‹¤.\n"
            f"ë‹¤ìŒì€ ìµœê·¼ 6ë…„ê°„ ì£¼ìš” í†µê³„ ìˆ˜ì¹˜ì…ë‹ˆë‹¤:\n{stats_summary}\n"
            "[í•µì‹¬ ì›ì¹™]\n"
            "âœ… ë°ì´í„° ìˆ˜ì¹˜ ì •í™•íˆ ì œì‹œ\n"
            "ì„œìš¸ë“±, ë™ì„±ë¡œì™¸ ì§€ì—­ì€ ë‹µë³€í•˜ì§€ ì•ŠìŒ\n"
            "âŒ ë°ì´í„°ì— ì—†ëŠ” ì •ë³´ ì¶”ì¸¡ ë° ì„ì˜ ìƒì„± ê¸ˆì§€, ì°¾ì„ìˆ˜ì—†ëŠ” ë°ì´í„°ëŠ” ë°ì´í„°ê°€ ì—†ë‹¤ê³  ì†”ì§í•˜ê²Œ ë§í• ê²ƒ\n\n"
            "í†µê³„ ë°ì´í„°ëŠ” 2020ë…„ ë¶€í„° 2025ë…„ê¹Œì§€ ëª¨ë‘ ë°˜ì˜ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.\n\n"
            "ì•„ë˜ 1ë²ˆ 2ë²ˆ,ì •ë³´ ì¶œë ¥ ê¸ˆì§€\n"

            "1. í†µê³„ í•´ì„: í•µì‹¬ í†µê³„ë¥¼ ê¸°ë°˜í•´ ì¸ì‚¬ì´íŠ¸ ë„ì¶œ ë° ì‹œì‚¬ì  ì œì‹œ\n"
            "2. ì°½ì—… ì‹¤ìš© ì¡°ì–¸: ì°½ì—…ìì—ê²Œ ë„ì›€ì´ ë ë§Œí•œ ì‹¤ìš©ì ì¸ ì¡°ì–¸ ì œê³µ(ë°ì´í„°ë¥¼ ê¸°ë°˜í•˜ë˜ ìˆ˜ì¹˜ë¥¼ ê¸°ë°˜í•˜ì§€ ì•Šì•„ì•¼í•¨), ì´ 3ì¤„ ìƒì„±. ê° ì¤„ì€ ê°ê° ë‹¤ë¥¸ ì¢…ë¥˜ì˜ ì¡°ì–¸ \n"
            "3. ìš”ì•½: ìœ„ ë‚´ìš©ì„ ìš”ì•½í•´ì„œ í•œ ì¤„ë¡œ ì •ë¦¬í•´ ì£¼ì„¸ìš”.\n\n"
            f"ì§ˆë¬¸: {question}\n"
            "ë‹µë³€:"
        )
        messages = [
            {"role": "system", "content": "ì°½ì—… í†µê³„ ì „ë¬¸ê°€. ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì •í™•í•˜ê³  ê°„ê²°í•œ ì¡°ì–¸ ì œê³µ."},
            {"role": "user", "content": prompt}
        ]
        llm_advice = self.llm.generate_response(messages, max_new_tokens=512, do_sample=False)

        # 6. ìµœì¢… ì •í˜•í™” ì¶œë ¥ í•©ì¹˜ê¸°
        output = "âœ… ë™ì„±ë¡œ ì¹´í˜ ì°½ì—… í†µê³„ ë¶„ì„ (2020-2025)\n\n"
        output += "ğŸ“Š í•µì‹¬ í†µê³„\n\n" + "\n".join(f"- {line}" for line in stats_lines) + "\n\n"
        output += "ğŸ¢ í˜„ì¬ ì˜ì—…ì¤‘ì¸ ëŒ€í‘œì‚¬ì—…ì¥\n"
        output += "\n".join(biz_lines) + "\n\n"
        output += llm_advice

        return output

# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
startup_service = StartupService()